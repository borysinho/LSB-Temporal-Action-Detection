{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b964f79b",
   "metadata": {},
   "source": [
    "# üéØ LSB Temporal Action Detection - Google Colab\n",
    "\n",
    "Sistema de detecci√≥n temporal de acciones para Lengua de Se√±as Boliviana (LSB)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Antes de empezar:\n",
    "\n",
    "1. **Configura GPU**: Runtime ‚Üí Change runtime type ‚Üí **T4 GPU**\n",
    "2. **Duraci√≥n**: ~2-4 horas para entrenamiento completo\n",
    "3. **Espacio**: ~10-15GB necesarios\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Hardware Recomendado:\n",
    "- **GPU**: T4 (16GB VRAM) ‚úÖ RECOMENDADO\n",
    "- **RAM**: 12GB High-RAM\n",
    "\n",
    "**¬øPor qu√© T4 GPU y no TPU?**\n",
    "- Video Swin Transformer optimizado para CUDA\n",
    "- PyTorch nativo (TPU requiere JAX/TensorFlow)\n",
    "- Mejor soporte para transformers y timm\n",
    "- 16GB VRAM suficiente para videos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89590043",
   "metadata": {},
   "source": [
    "## üîß 1. Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar GPU disponible\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2195399",
   "metadata": {},
   "source": [
    "## üì¶ 2. Clonar Repositorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar repositorio\n",
    "!git clone https://github.com/borysinho/LSB-Temporal-Action-Detection.git\n",
    "%cd LSB-Temporal-Action-Detection\n",
    "\n",
    "# Ver estructura\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585686cc",
   "metadata": {},
   "source": [
    "## üì• 3. Instalar Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar PyTorch con CUDA (optimizado para Colab T4)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar resto de dependencias\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "print(\"‚úÖ Instalaci√≥n completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d33b2",
   "metadata": {},
   "source": [
    "## üíæ 4. Conectar Google Drive (Opcional pero Recomendado)\n",
    "\n",
    "Para:\n",
    "- Guardar checkpoints\n",
    "- Cargar tus videos\n",
    "- Persistir resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d2d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Crear directorios en Drive\n",
    "import os\n",
    "DRIVE_PATH = '/content/drive/MyDrive/LSB_TAD'\n",
    "os.makedirs(f\"{DRIVE_PATH}/checkpoints\", exist_ok=True)\n",
    "os.makedirs(f\"{DRIVE_PATH}/logs\", exist_ok=True)\n",
    "os.makedirs(f\"{DRIVE_PATH}/data\", exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Google Drive montado en: {DRIVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93820e5",
   "metadata": {},
   "source": [
    "## üìÅ 5. Preparar Datos\n",
    "\n",
    "### Opci√≥n A: Subir desde tu Drive\n",
    "Sube tus videos a `MyDrive/LSB_TAD/data/videos/`\n",
    "\n",
    "**IMPORTANTE**: Tambi√©n debes subir las carpetas de segmentos procesados. Cada video debe tener su carpeta correspondiente con los segmentos:\n",
    "- Si tu video se llama `ABECEDARIO.mp4`, debe existir `ABECEDARIO_senas/` con los segmentos\n",
    "- Sube estas carpetas a la misma ubicaci√≥n: `MyDrive/LSB_TAD/data/videos/`\n",
    "\n",
    "### Opci√≥n B: Descargar desde URL\n",
    "Si tienes tus datos en la nube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b319c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar rutas de datos\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Opci√≥n A: Usar datos desde Google Drive\n",
    "USE_DRIVE = True\n",
    "\n",
    "if USE_DRIVE:\n",
    "    VIDEO_DIR = f\"{DRIVE_PATH}/data/videos\"\n",
    "    CHECKPOINT_DIR = f\"{DRIVE_PATH}/checkpoints\"\n",
    "    LOG_DIR = f\"{DRIVE_PATH}/logs\"\n",
    "else:\n",
    "    # Opci√≥n B: Usar almacenamiento local de Colab (se pierde al desconectar)\n",
    "    VIDEO_DIR = \"/content/data/videos\"\n",
    "    CHECKPOINT_DIR = \"/content/checkpoints\"\n",
    "    LOG_DIR = \"/content/logs\"\n",
    "    os.makedirs(VIDEO_DIR, exist_ok=True)\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Videos: {VIDEO_DIR}\")\n",
    "print(f\"üíæ Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"üìä Logs: {LOG_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Descargar datos de ejemplo (si tienes URL)\n",
    "# Descomenta y ajusta seg√∫n tu caso\n",
    "\n",
    "# !wget -O /tmp/lsb_videos.zip \"TU_URL_AQUI\"\n",
    "# !unzip /tmp/lsb_videos.zip -d {VIDEO_DIR}\n",
    "# !rm /tmp/lsb_videos.zip\n",
    "\n",
    "print(\"‚ö†Ô∏è Aseg√∫rate de tener videos en:\", VIDEO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce906d3",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è 7. Preparar Anotaciones Temporales\n",
    "\n",
    "Crear archivo de anotaciones con timestamps de se√±as\n",
    "\n",
    "**Nota**: Aseg√∫rate de que tanto los videos como sus carpetas de segmentos est√©n en Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec5b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso auxiliar: Crear estructura de segmentos si no existe\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "print(\"üîß Verificando y creando estructura de segmentos...\")\n",
    "\n",
    "# Funci√≥n para crear carpetas de segmentos b√°sicas\n",
    "def create_segment_structure(videos_dir):\n",
    "    \"\"\"Crea carpetas de segmentos vac√≠as para videos que no las tienen.\"\"\"\n",
    "    videos_found = 0\n",
    "    segments_created = 0\n",
    "    \n",
    "    for video_file in Path(videos_dir).rglob(\"*.mp4\"):\n",
    "        video_name = video_file.stem\n",
    "        video_parent = video_file.parent\n",
    "        \n",
    "        # Verificar si existe carpeta de segmentos\n",
    "        segment_dir = video_parent / f\"{video_name}_senas\"\n",
    "        \n",
    "        if not segment_dir.exists():\n",
    "            # Crear carpeta vac√≠a\n",
    "            segment_dir.mkdir(exist_ok=True)\n",
    "            print(f\"üìÅ Creada carpeta de segmentos: {segment_dir}\")\n",
    "            segments_created += 1\n",
    "        \n",
    "        videos_found += 1\n",
    "        \n",
    "        # Limitar output para no saturar\n",
    "        if videos_found % 100 == 0:\n",
    "            print(f\"   Procesados {videos_found} videos...\")\n",
    "    \n",
    "    print(f\"‚úÖ Verificaci√≥n completada:\")\n",
    "    print(f\"   üìπ Videos encontrados: {videos_found}\")\n",
    "    print(f\"   üìÅ Carpetas de segmentos creadas: {segments_created}\")\n",
    "    \n",
    "    if segments_created > 0:\n",
    "        print(\"\\n‚ö†Ô∏è  IMPORTANTE:\")\n",
    "        print(\"   Se crearon carpetas de segmentos VAC√çAS.\")\n",
    "        print(\"   Debes subir los archivos de segmentos .mp4 a cada carpeta correspondiente.\")\n",
    "        print(\"   Cada carpeta _senas debe contener los clips individuales de se√±as.\")\n",
    "        print(\"\\n   Ejemplo:\")\n",
    "        print(\"   - TOMATE.mp4 ‚Üí TOMATE_senas/\")\n",
    "        print(\"     ‚îú‚îÄ‚îÄ se√±a_01_frames_0000-0360.mp4\")\n",
    "        print(\"     ‚îú‚îÄ‚îÄ se√±a_02_frames_0361-0720.mp4\")\n",
    "        print(\"     ‚îî‚îÄ‚îÄ ...\")\n",
    "    \n",
    "    return videos_found, segments_created\n",
    "\n",
    "# Ejecutar creaci√≥n de estructura\n",
    "videos_count, segments_created = create_segment_structure(VIDEO_DIR)\n",
    "\n",
    "if segments_created > 0:\n",
    "    print(f\"\\nüõë DETENTE AQU√ç: Sube los segmentos antes de continuar.\")\n",
    "    print(\"   Una vez que hayas subido todos los archivos de segmentos,\")\n",
    "    print(\"   ejecuta la siguiente celda.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Estructura completa detectada. Puedes continuar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866848f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que tenemos videos y detectar si est√°n segmentados\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "print(\"üîç Verificando estructura de datos...\")\n",
    "print(f\"üìÇ Directorio de videos: {VIDEO_DIR}\")\n",
    "\n",
    "# Contar videos\n",
    "video_count = len(list(Path(VIDEO_DIR).rglob(\"*.mp4\")))\n",
    "print(f\"üìπ Videos encontrados: {video_count}\")\n",
    "\n",
    "# Detectar si los videos est√°n pre-segmentados\n",
    "segmented_videos = []\n",
    "segment_dirs = []\n",
    "\n",
    "# Buscar patrones de videos segmentados (ej: ABECEDARIO_001.mp4, ABECEDARIO_002.mp4, etc.)\n",
    "for video_file in Path(VIDEO_DIR).rglob(\"*.mp4\"):\n",
    "    video_name = video_file.stem\n",
    "    # Buscar patr√≥n: nombre_base + _ + n√∫meros + .mp4\n",
    "    match = re.match(r'^(.+?)_(\\d+)\\.mp4$', video_file.name)\n",
    "    if match:\n",
    "        base_name = match.group(1)\n",
    "        segment_num = int(match.group(2))\n",
    "        segmented_videos.append((base_name, video_file))\n",
    "\n",
    "# Agrupar por base_name\n",
    "segmented_groups = {}\n",
    "for base_name, video_file in segmented_videos:\n",
    "    if base_name not in segmented_groups:\n",
    "        segmented_groups[base_name] = []\n",
    "    segmented_groups[base_name].append(video_file)\n",
    "\n",
    "# Verificar carpetas de segmentos tradicionales\n",
    "segment_dirs = list(Path(VIDEO_DIR).rglob(\"*_senas\"))\n",
    "\n",
    "print(f\"üìÅ Carpetas de segmentos tradicionales: {len(segment_dirs)}\")\n",
    "print(f\"üé¨ Grupos de videos segmentados detectados: {len(segmented_groups)}\")\n",
    "\n",
    "# An√°lisis detallado de las carpetas de segmentos\n",
    "if segment_dirs:\n",
    "    print(\"\\nüìã An√°lisis de carpetas de segmentos:\")\n",
    "    empty_dirs = 0\n",
    "    dirs_with_files = 0\n",
    "    total_segments = 0\n",
    "\n",
    "    # Contar TODAS las carpetas, no solo las primeras 10\n",
    "    for seg_dir in segment_dirs:\n",
    "        mp4_files = list(seg_dir.glob(\"*.mp4\"))\n",
    "        if mp4_files:\n",
    "            dirs_with_files += 1\n",
    "            total_segments += len(mp4_files)\n",
    "        else:\n",
    "            empty_dirs += 1\n",
    "\n",
    "    # Mostrar detalles de las primeras 10\n",
    "    print(\"  Primeras 10 carpetas:\")\n",
    "    for i, seg_dir in enumerate(segment_dirs[:10]):\n",
    "        mp4_files = list(seg_dir.glob(\"*.mp4\"))\n",
    "        if mp4_files:\n",
    "            print(f\"  ‚úì {seg_dir.name}: {len(mp4_files)} segmentos\")\n",
    "        else:\n",
    "            print(f\"  ‚úó {seg_dir.name}: VAC√çA\")\n",
    "\n",
    "    if len(segment_dirs) > 10:\n",
    "        print(f\"  ... y {len(segment_dirs) - 10} carpetas m√°s\")\n",
    "\n",
    "    print(f\"\\nüìä Resumen de segmentos:\")\n",
    "    print(f\"   üìÅ Carpetas con archivos: {dirs_with_files}\")\n",
    "    print(f\"   üìÅ Carpetas vac√≠as: {empty_dirs}\")\n",
    "    print(f\"   üé¨ Total de segmentos encontrados: {total_segments}\")\n",
    "\n",
    "# Detectar si todos los videos son segmentos individuales\n",
    "videos_with_segments = 0\n",
    "videos_without_segments = 0\n",
    "\n",
    "for video_file in Path(VIDEO_DIR).rglob(\"*.mp4\"):\n",
    "    video_name = video_file.stem\n",
    "    video_parent = video_file.parent\n",
    "\n",
    "    # Verificar si existe carpeta de segmentos\n",
    "    segment_dir = video_parent / f\"{video_name}_senas\"\n",
    "    if segment_dir.exists() and list(segment_dir.glob(\"*.mp4\")):\n",
    "        videos_with_segments += 1\n",
    "    else:\n",
    "        videos_without_segments += 1\n",
    "\n",
    "if video_count == 0:\n",
    "    print(\"‚ùå ERROR: No se encontraron videos. Sube tus videos a Drive primero.\")\n",
    "elif videos_with_segments == 0 and videos_without_segments > 0 and len(segment_dirs) == 0:\n",
    "    print(\"üéØ DETECTADO: Todos los archivos .mp4 son segmentos individuales.\")\n",
    "    print(\"   El sistema procesar√° cada archivo como un segmento independiente.\")\n",
    "    print(\"   No se requieren carpetas *_senas ni videos completos.\")\n",
    "    segments_dir = VIDEO_DIR\n",
    "elif len(segment_dirs) > 0 and empty_dirs == len(segment_dirs) and len(segmented_groups) == 0:\n",
    "    print(\"‚ö†Ô∏è  DETECTADO: Todas las carpetas *_senas est√°n vac√≠as.\")\n",
    "    print(\"   El sistema buscar√° autom√°ticamente videos pre-segmentados.\")\n",
    "    print(\"   Aseg√∫rate de que tus segmentos est√©n en el mismo directorio que los videos\")\n",
    "    print(\"   con nombres como: NOMBRE_001.mp4, NOMBRE_002.mp4, etc.\")\n",
    "    segments_dir = VIDEO_DIR\n",
    "elif len(segment_dirs) > 0:\n",
    "    print(\"‚úÖ Detectadas carpetas de segmentos tradicionales. Usando estructura de carpetas...\")\n",
    "    segments_dir = VIDEO_DIR\n",
    "elif len(segmented_groups) > 0:\n",
    "    print(\"‚úÖ Detectados videos pre-segmentados. Procesando directamente...\")\n",
    "    segments_dir = VIDEO_DIR\n",
    "else:\n",
    "    print(\"‚ùå ERROR: No se encontraron segmentos ni videos pre-segmentados.\")\n",
    "    print(\"   Aseg√∫rate de subir las carpetas *_senas o videos segmentados con patr√≥n nombre_001.mp4, nombre_002.mp4, etc.\")\n",
    "\n",
    "if video_count > 0 and (len(segment_dirs) > 0 or len(segmented_groups) > 0 or (videos_with_segments == 0 and videos_without_segments > 0)):\n",
    "    print(\"‚úÖ Estructura correcta detectada. Procediendo con preparaci√≥n de anotaciones...\")\n",
    "\n",
    "    # Crear anotaciones temporales usando el script optimizado\n",
    "    !python scripts/prepare_annotations_fast.py \\\n",
    "        --videos_dir {VIDEO_DIR} \\\n",
    "        --segments_dir {segments_dir} \\\n",
    "        --output_dir data/annotations \\\n",
    "        --train_ratio 0.7 \\\n",
    "        --val_ratio 0.15 \\\n",
    "        --test_ratio 0.15\n",
    "\n",
    "    print(\"‚úÖ Anotaciones preparadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386f0c0",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 8. Configuraci√≥n del Modelo\n",
    "\n",
    "Ajustar configuraci√≥n para Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a783ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y modificar configuraci√≥n\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Ajustes para Colab T4 GPU (16GB VRAM)\n",
    "config['data']['videos_dir'] = VIDEO_DIR\n",
    "config['training']['batch_size'] = 4  # Ajustar seg√∫n memoria disponible\n",
    "config['training']['num_epochs'] = 100  # Puedes reducir para pruebas\n",
    "config['training']['num_workers'] = 2  # Colab tiene 2 CPUs\n",
    "config['training']['checkpoint_dir'] = CHECKPOINT_DIR\n",
    "config['training']['log_dir'] = LOG_DIR\n",
    "\n",
    "# Activar mixed precision para T4\n",
    "config['training']['mixed_precision'] = True  # FP16 para mejor rendimiento\n",
    "\n",
    "# Guardar configuraci√≥n modificada\n",
    "with open('config_colab.yaml', 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n ajustada para Colab T4 GPU\")\n",
    "print(f\"   - Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"   - Epochs: {config['training']['num_epochs']}\")\n",
    "print(f\"   - Mixed Precision: {config['training']['mixed_precision']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc924db5",
   "metadata": {},
   "source": [
    "## üöÄ 9. Entrenamiento\n",
    "\n",
    "### Opci√≥n A: Entrenar desde cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar desde cero\n",
    "!python scripts/train.py \\\n",
    "    --config config_colab.yaml \\\n",
    "    --experiment_name \"lsb_tad_v1\"\n",
    "\n",
    "print(\"‚úÖ Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97c8af",
   "metadata": {},
   "source": [
    "### Opci√≥n B: Reanudar entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f36692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reanudar desde checkpoint (√∫til si Colab se desconecta)\n",
    "CHECKPOINT_PATH = f\"{CHECKPOINT_DIR}/epoch_50.pth\"  # Ajustar al √∫ltimo checkpoint\n",
    "\n",
    "!python scripts/train.py \\\n",
    "    --config config_colab.yaml \\\n",
    "    --resume {CHECKPOINT_PATH}\n",
    "\n",
    "print(\"‚úÖ Entrenamiento reanudado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00b81db",
   "metadata": {},
   "source": [
    "## üìä 10. Monitoreo con TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb99ff",
   "metadata": {},
   "source": [
    "## üéØ 11. Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo en test set\n",
    "!python scripts/evaluate.py \\\n",
    "    --config config_colab.yaml \\\n",
    "    --checkpoint {CHECKPOINT_DIR}/best_model.pth \\\n",
    "    --split test \\\n",
    "    --output_dir results\n",
    "\n",
    "# Mostrar m√©tricas\n",
    "import json\n",
    "with open('results/metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS FINALES\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15918d9",
   "metadata": {},
   "source": [
    "## üîÆ 12. Inferencia en Video Nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a816205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencia en un video\n",
    "import torch\n",
    "from models.complete_model import build_model\n",
    "from utils.video_utils import load_video\n",
    "from utils.visualization import visualize_detections\n",
    "import cv2\n",
    "from IPython.display import Video, display\n",
    "\n",
    "# Cargar modelo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = build_model(config)\n",
    "checkpoint = torch.load(f\"{CHECKPOINT_DIR}/best_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Modelo cargado\")\n",
    "\n",
    "# Procesar video\n",
    "VIDEO_PATH = f\"{VIDEO_DIR}/test_video.mp4\"  # Ajustar ruta\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Cargar video\n",
    "    frames = load_video(VIDEO_PATH, num_frames=64)\n",
    "    frames = frames.unsqueeze(0).to(device)  # (1, 3, T, H, W)\n",
    "    \n",
    "    # Inferencia\n",
    "    outputs = model(frames)\n",
    "    \n",
    "    # Post-procesamiento\n",
    "    detections = outputs['detections']  # [(start, end, class, score), ...]\n",
    "    \n",
    "    print(f\"\\nüéØ Detectadas {len(detections)} se√±as:\")\n",
    "    for i, det in enumerate(detections):\n",
    "        start, end, class_id, score = det\n",
    "        print(f\"  {i+1}. Se√±a {class_id}: frames {start}-{end} (confianza: {score:.3f})\")\n",
    "\n",
    "# Visualizar resultados\n",
    "output_path = \"/content/output_visualized.mp4\"\n",
    "visualize_detections(VIDEO_PATH, detections, output_path)\n",
    "\n",
    "# Mostrar video con detecciones\n",
    "display(Video(output_path, width=640, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a906ea",
   "metadata": {},
   "source": [
    "## üì¶ 13. Inferencia en Lote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar m√∫ltiples videos\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = f\"{VIDEO_DIR}/test_videos\"\n",
    "output_dir = \"/content/predictions\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "video_files = glob.glob(f\"{input_dir}/*.mp4\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for video_path in tqdm(video_files, desc=\"Procesando videos\"):\n",
    "    video_name = Path(video_path).stem\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        frames = load_video(video_path, num_frames=64)\n",
    "        frames = frames.unsqueeze(0).to(device)\n",
    "        \n",
    "        outputs = model(frames)\n",
    "        detections = outputs['detections']\n",
    "        \n",
    "        results[video_name] = detections\n",
    "\n",
    "# Guardar resultados\n",
    "import pickle\n",
    "with open(f\"{output_dir}/batch_predictions.pkl\", 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(f\"‚úÖ {len(results)} videos procesados\")\n",
    "print(f\"   Resultados guardados en: {output_dir}/batch_predictions.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bc1a3",
   "metadata": {},
   "source": [
    "## üíæ 14. Exportar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996fc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a ONNX para producci√≥n\n",
    "dummy_input = torch.randn(1, 3, 64, 224, 224).to(device)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    f\"{CHECKPOINT_DIR}/model.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=14,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['video'],\n",
    "    output_names=['detections'],\n",
    "    dynamic_axes={\n",
    "        'video': {0: 'batch_size'},\n",
    "        'detections': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Modelo exportado a ONNX: {CHECKPOINT_DIR}/model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a480d9",
   "metadata": {},
   "source": [
    "## üì• 15. Descargar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659612d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprimir resultados para descarga\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Crear ZIP con resultados importantes\n",
    "shutil.make_archive('/content/lsb_tad_results', 'zip', '.', \n",
    "                    base_dir=None)\n",
    "\n",
    "# Agregar a ZIP:\n",
    "!zip -r /content/lsb_tad_results.zip \\\n",
    "    {CHECKPOINT_DIR}/best_model.pth \\\n",
    "    {CHECKPOINT_DIR}/model.onnx \\\n",
    "    results/ \\\n",
    "    config_colab.yaml\n",
    "\n",
    "# Descargar\n",
    "files.download('/content/lsb_tad_results.zip')\n",
    "\n",
    "print(\"‚úÖ Descarga iniciada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a9d39",
   "metadata": {},
   "source": [
    "## üí° 16. Tips y Troubleshooting\n",
    "\n",
    "### ‚ö†Ô∏è Si te quedas sin memoria (CUDA OOM):\n",
    "```python\n",
    "# Reducir batch size\n",
    "config['training']['batch_size'] = 2\n",
    "\n",
    "# Reducir resoluci√≥n de entrada\n",
    "config['data']['input_size'] = 192  # en vez de 224\n",
    "\n",
    "# Reducir longitud de clips\n",
    "config['data']['clip_length'] = 32  # en vez de 64\n",
    "```\n",
    "\n",
    "### üîÑ Si Colab se desconecta:\n",
    "- Los checkpoints est√°n en Google Drive (si usaste `USE_DRIVE=True`)\n",
    "- Simplemente ejecuta la celda de \"Reanudar entrenamiento\"\n",
    "\n",
    "### üìä Monitorear uso de GPU:\n",
    "```python\n",
    "!watch -n 1 nvidia-smi\n",
    "```\n",
    "\n",
    "### üöÄ Acelerar entrenamiento:\n",
    "1. **Mixed Precision (FP16)**: Ya activado en config\n",
    "2. **Gradient Accumulation**: Si batch size es muy peque√±o\n",
    "3. **DataLoader workers**: Ajustar `num_workers`\n",
    "\n",
    "### üìà Mejorar precisi√≥n:\n",
    "1. Aumentar epochs\n",
    "2. Usar data augmentation m√°s agresivo\n",
    "3. Ajustar learning rate\n",
    "4. Usar learning rate scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ab60e",
   "metadata": {},
   "source": [
    "## üìà 17. Monitoreo en Tiempo Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitorear progreso de entrenamiento\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def plot_training_progress(log_file):\n",
    "    \"\"\"Graficar progreso en tiempo real.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(log_file)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss\n",
    "        axes[0, 0].plot(df['epoch'], df['train_loss'], label='Train')\n",
    "        axes[0, 0].plot(df['epoch'], df['val_loss'], label='Val')\n",
    "        axes[0, 0].set_title('Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # mAP\n",
    "        axes[0, 1].plot(df['epoch'], df['val_map'])\n",
    "        axes[0, 1].set_title('mAP@0.5')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # Learning Rate\n",
    "        axes[1, 0].plot(df['epoch'], df['lr'])\n",
    "        axes[1, 0].set_title('Learning Rate')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_yscale('log')\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # GPU Memory\n",
    "        if 'gpu_memory' in df.columns:\n",
    "            axes[1, 1].plot(df['epoch'], df['gpu_memory'])\n",
    "            axes[1, 1].set_title('GPU Memory (GB)')\n",
    "            axes[1, 1].set_xlabel('Epoch')\n",
    "            axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al graficar: {e}\")\n",
    "\n",
    "# Actualizar cada 30 segundos durante entrenamiento\n",
    "LOG_FILE = f\"{LOG_DIR}/training.csv\"\n",
    "\n",
    "# Descomentar para monitoreo en tiempo real (ejecutar en celda separada)\n",
    "# while True:\n",
    "#     clear_output(wait=True)\n",
    "#     plot_training_progress(LOG_FILE)\n",
    "#     time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efdba6",
   "metadata": {},
   "source": [
    "## üßπ 18. Limpieza (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar archivos temporales para liberar espacio\n",
    "!rm -rf /tmp/*\n",
    "!rm -rf ~/.cache/pip\n",
    "!rm -rf data/cache/*\n",
    "\n",
    "# Ver espacio disponible\n",
    "!df -h /content\n",
    "\n",
    "print(\"‚úÖ Limpieza completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b5916",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Recursos Adicionales\n",
    "\n",
    "- **Repositorio**: https://github.com/borysinho/LSB-Temporal-Action-Detection\n",
    "- **Paper Video Swin**: [Video Swin Transformer](https://arxiv.org/abs/2106.13230)\n",
    "- **Documentaci√≥n PyTorch**: https://pytorch.org/docs/\n",
    "\n",
    "---\n",
    "\n",
    "## üìû Soporte\n",
    "\n",
    "¬øProblemas o preguntas? Abre un issue en GitHub.\n",
    "\n",
    "---\n",
    "\n",
    "**Creado con ‚ù§Ô∏è para la comunidad LSB**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
