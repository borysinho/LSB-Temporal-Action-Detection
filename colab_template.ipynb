{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b964f79b",
   "metadata": {},
   "source": [
    "# üéØ LSB Temporal Action Detection - Google Colab\n",
    "\n",
    "Sistema de detecci√≥n temporal de acciones para Lengua de Se√±as Boliviana (LSB)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Antes de empezar:\n",
    "\n",
    "1. **Configura GPU**: Runtime ‚Üí Change runtime type ‚Üí **T4 GPU**\n",
    "2. **Duraci√≥n**: ~2-4 horas para entrenamiento completo\n",
    "3. **Espacio**: ~10-15GB necesarios\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Hardware Recomendado:\n",
    "- **GPU**: T4 (16GB VRAM) ‚úÖ RECOMENDADO\n",
    "- **RAM**: 12GB High-RAM\n",
    "\n",
    "**¬øPor qu√© T4 GPU y no TPU?**\n",
    "- Video Swin Transformer optimizado para CUDA\n",
    "- PyTorch nativo (TPU requiere JAX/TensorFlow)\n",
    "- Mejor soporte para transformers y timm\n",
    "- 16GB VRAM suficiente para videos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89590043",
   "metadata": {},
   "source": [
    "## üîß 1. Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar GPU disponible\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2195399",
   "metadata": {},
   "source": [
    "## üì¶ 2. Clonar Repositorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar repositorio\n",
    "!git clone https://github.com/borysinho/LSB-Temporal-Action-Detection.git\n",
    "%cd LSB-Temporal-Action-Detection\n",
    "\n",
    "# Ver estructura\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585686cc",
   "metadata": {},
   "source": [
    "## üì• 3. Instalar Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar PyTorch con CUDA (optimizado para Colab T4)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar resto de dependencias\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "print(\"‚úÖ Instalaci√≥n completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d33b2",
   "metadata": {},
   "source": [
    "## üíæ 4. Conectar Google Drive (Opcional pero Recomendado)\n",
    "\n",
    "Para:\n",
    "- Guardar checkpoints\n",
    "- Cargar tus videos\n",
    "- Persistir resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d2d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Crear directorios en Drive\n",
    "import os\n",
    "DRIVE_PATH = '/content/drive/MyDrive/LSB_TAD'\n",
    "os.makedirs(f\"{DRIVE_PATH}/checkpoints\", exist_ok=True)\n",
    "os.makedirs(f\"{DRIVE_PATH}/logs\", exist_ok=True)\n",
    "os.makedirs(f\"{DRIVE_PATH}/data\", exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Google Drive montado en: {DRIVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93820e5",
   "metadata": {},
   "source": [
    "## üìÅ 5. Preparar Datos\n",
    "\n",
    "### Opci√≥n A: Subir desde tu Drive\n",
    "Sube tus videos a `MyDrive/LSB_TAD/data/videos/`\n",
    "\n",
    "### Opci√≥n B: Descargar desde URL\n",
    "Si tienes tus datos en la nube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b319c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar rutas de datos\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Opci√≥n A: Usar datos desde Google Drive\n",
    "USE_DRIVE = True\n",
    "\n",
    "if USE_DRIVE:\n",
    "    VIDEO_DIR = f\"{DRIVE_PATH}/data/videos\"\n",
    "    CHECKPOINT_DIR = f\"{DRIVE_PATH}/checkpoints\"\n",
    "    LOG_DIR = f\"{DRIVE_PATH}/logs\"\n",
    "else:\n",
    "    # Opci√≥n B: Usar almacenamiento local de Colab (se pierde al desconectar)\n",
    "    VIDEO_DIR = \"/content/data/videos\"\n",
    "    CHECKPOINT_DIR = \"/content/checkpoints\"\n",
    "    LOG_DIR = \"/content/logs\"\n",
    "    os.makedirs(VIDEO_DIR, exist_ok=True)\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Videos: {VIDEO_DIR}\")\n",
    "print(f\"üíæ Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"üìä Logs: {LOG_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Descargar datos de ejemplo (si tienes URL)\n",
    "# Descomenta y ajusta seg√∫n tu caso\n",
    "\n",
    "# !wget -O /tmp/lsb_videos.zip \"TU_URL_AQUI\"\n",
    "# !unzip /tmp/lsb_videos.zip -d {VIDEO_DIR}\n",
    "# !rm /tmp/lsb_videos.zip\n",
    "\n",
    "print(\"‚ö†Ô∏è Aseg√∫rate de tener videos en:\", VIDEO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce906d3",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è 6. Preparar Anotaciones Temporales\n",
    "\n",
    "Crear archivo de anotaciones con timestamps de se√±as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866848f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear anotaciones temporales usando el script optimizado\n",
    "!python scripts/prepare_annotations_fast.py \\\n",
    "    --videos_dir {VIDEO_DIR} \\\n",
    "    --segments_dir {VIDEO_DIR} \\\n",
    "    --output_dir data/annotations \\\n",
    "    --train_ratio 0.7 \\\n",
    "    --val_ratio 0.15 \\\n",
    "    --test_ratio 0.15\n",
    "\n",
    "print(\"‚úÖ Anotaciones preparadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386f0c0",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 7. Configuraci√≥n del Modelo\n",
    "\n",
    "Ajustar configuraci√≥n para Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a783ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y modificar configuraci√≥n\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Ajustes para Colab T4 GPU (16GB VRAM)\n",
    "config['data']['videos_dir'] = VIDEO_DIR\n",
    "config['training']['batch_size'] = 4  # Ajustar seg√∫n memoria disponible\n",
    "config['training']['num_epochs'] = 100  # Puedes reducir para pruebas\n",
    "config['training']['num_workers'] = 2  # Colab tiene 2 CPUs\n",
    "config['training']['checkpoint_dir'] = CHECKPOINT_DIR\n",
    "config['training']['log_dir'] = LOG_DIR\n",
    "\n",
    "# Activar mixed precision para T4\n",
    "config['training']['mixed_precision'] = True  # FP16 para mejor rendimiento\n",
    "\n",
    "# Guardar configuraci√≥n modificada\n",
    "with open('config_colab.yaml', 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n ajustada para Colab T4 GPU\")\n",
    "print(f\"   - Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"   - Epochs: {config['training']['num_epochs']}\")\n",
    "print(f\"   - Mixed Precision: {config['training']['mixed_precision']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc924db5",
   "metadata": {},
   "source": [
    "## üöÄ 8. Entrenamiento\n",
    "\n",
    "### Opci√≥n A: Entrenar desde cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar desde cero\n",
    "!python scripts/train.py \\\n",
    "    --config config_colab.yaml \\\n",
    "    --gpu 0 \\\n",
    "    --experiment_name \"lsb_tad_v1\"\n",
    "\n",
    "print(\"‚úÖ Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97c8af",
   "metadata": {},
   "source": [
    "### Opci√≥n B: Reanudar entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f36692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reanudar desde checkpoint (√∫til si Colab se desconecta)\n",
    "CHECKPOINT_PATH = f\"{CHECKPOINT_DIR}/epoch_50.pth\"  # Ajustar al √∫ltimo checkpoint\n",
    "\n",
    "!python scripts/train.py \\\n",
    "    --config config_colab.yaml \\\n",
    "    --resume {CHECKPOINT_PATH} \\\n",
    "    --gpu 0\n",
    "\n",
    "print(\"‚úÖ Entrenamiento reanudado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00b81db",
   "metadata": {},
   "source": [
    "## üìä 9. Monitoreo con TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb99ff",
   "metadata": {},
   "source": [
    "## üéØ 10. Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo en test set\n",
    "!python scripts/evaluate.py \\\n",
    "    --config config_colab.yaml \\\n",
    "    --checkpoint {CHECKPOINT_DIR}/best_model.pth \\\n",
    "    --split test \\\n",
    "    --output_dir results\n",
    "\n",
    "# Mostrar m√©tricas\n",
    "import json\n",
    "with open('results/metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS FINALES\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15918d9",
   "metadata": {},
   "source": [
    "## üîÆ 11. Inferencia en Video Nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a816205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencia en un video\n",
    "import torch\n",
    "from models.complete_model import build_model\n",
    "from utils.video_utils import load_video\n",
    "from utils.visualization import visualize_detections\n",
    "import cv2\n",
    "from IPython.display import Video, display\n",
    "\n",
    "# Cargar modelo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = build_model(config)\n",
    "checkpoint = torch.load(f\"{CHECKPOINT_DIR}/best_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Modelo cargado\")\n",
    "\n",
    "# Procesar video\n",
    "VIDEO_PATH = f\"{VIDEO_DIR}/test_video.mp4\"  # Ajustar ruta\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Cargar video\n",
    "    frames = load_video(VIDEO_PATH, num_frames=64)\n",
    "    frames = frames.unsqueeze(0).to(device)  # (1, 3, T, H, W)\n",
    "    \n",
    "    # Inferencia\n",
    "    outputs = model(frames)\n",
    "    \n",
    "    # Post-procesamiento\n",
    "    detections = outputs['detections']  # [(start, end, class, score), ...]\n",
    "    \n",
    "    print(f\"\\nüéØ Detectadas {len(detections)} se√±as:\")\n",
    "    for i, det in enumerate(detections):\n",
    "        start, end, class_id, score = det\n",
    "        print(f\"  {i+1}. Se√±a {class_id}: frames {start}-{end} (confianza: {score:.3f})\")\n",
    "\n",
    "# Visualizar resultados\n",
    "output_path = \"/content/output_visualized.mp4\"\n",
    "visualize_detections(VIDEO_PATH, detections, output_path)\n",
    "\n",
    "# Mostrar video con detecciones\n",
    "display(Video(output_path, width=640, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a906ea",
   "metadata": {},
   "source": [
    "## üì¶ 12. Inferencia en Lote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar m√∫ltiples videos\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = f\"{VIDEO_DIR}/test_videos\"\n",
    "output_dir = \"/content/predictions\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "video_files = glob.glob(f\"{input_dir}/*.mp4\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for video_path in tqdm(video_files, desc=\"Procesando videos\"):\n",
    "    video_name = Path(video_path).stem\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        frames = load_video(video_path, num_frames=64)\n",
    "        frames = frames.unsqueeze(0).to(device)\n",
    "        \n",
    "        outputs = model(frames)\n",
    "        detections = outputs['detections']\n",
    "        \n",
    "        results[video_name] = detections\n",
    "\n",
    "# Guardar resultados\n",
    "import pickle\n",
    "with open(f\"{output_dir}/batch_predictions.pkl\", 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(f\"‚úÖ {len(results)} videos procesados\")\n",
    "print(f\"   Resultados guardados en: {output_dir}/batch_predictions.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bc1a3",
   "metadata": {},
   "source": [
    "## üíæ 13. Exportar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996fc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a ONNX para producci√≥n\n",
    "dummy_input = torch.randn(1, 3, 64, 224, 224).to(device)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    f\"{CHECKPOINT_DIR}/model.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=14,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['video'],\n",
    "    output_names=['detections'],\n",
    "    dynamic_axes={\n",
    "        'video': {0: 'batch_size'},\n",
    "        'detections': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Modelo exportado a ONNX: {CHECKPOINT_DIR}/model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a480d9",
   "metadata": {},
   "source": [
    "## üì• 14. Descargar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659612d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprimir resultados para descarga\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Crear ZIP con resultados importantes\n",
    "shutil.make_archive('/content/lsb_tad_results', 'zip', '.', \n",
    "                    base_dir=None)\n",
    "\n",
    "# Agregar a ZIP:\n",
    "!zip -r /content/lsb_tad_results.zip \\\n",
    "    {CHECKPOINT_DIR}/best_model.pth \\\n",
    "    {CHECKPOINT_DIR}/model.onnx \\\n",
    "    results/ \\\n",
    "    config_colab.yaml\n",
    "\n",
    "# Descargar\n",
    "files.download('/content/lsb_tad_results.zip')\n",
    "\n",
    "print(\"‚úÖ Descarga iniciada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a9d39",
   "metadata": {},
   "source": [
    "## üí° 15. Tips y Troubleshooting\n",
    "\n",
    "### ‚ö†Ô∏è Si te quedas sin memoria (CUDA OOM):\n",
    "```python\n",
    "# Reducir batch size\n",
    "config['training']['batch_size'] = 2\n",
    "\n",
    "# Reducir resoluci√≥n de entrada\n",
    "config['data']['input_size'] = 192  # en vez de 224\n",
    "\n",
    "# Reducir longitud de clips\n",
    "config['data']['clip_length'] = 32  # en vez de 64\n",
    "```\n",
    "\n",
    "### üîÑ Si Colab se desconecta:\n",
    "- Los checkpoints est√°n en Google Drive (si usaste `USE_DRIVE=True`)\n",
    "- Simplemente ejecuta la celda de \"Reanudar entrenamiento\"\n",
    "\n",
    "### üìä Monitorear uso de GPU:\n",
    "```python\n",
    "!watch -n 1 nvidia-smi\n",
    "```\n",
    "\n",
    "### üöÄ Acelerar entrenamiento:\n",
    "1. **Mixed Precision (FP16)**: Ya activado en config\n",
    "2. **Gradient Accumulation**: Si batch size es muy peque√±o\n",
    "3. **DataLoader workers**: Ajustar `num_workers`\n",
    "\n",
    "### üìà Mejorar precisi√≥n:\n",
    "1. Aumentar epochs\n",
    "2. Usar data augmentation m√°s agresivo\n",
    "3. Ajustar learning rate\n",
    "4. Usar learning rate scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ab60e",
   "metadata": {},
   "source": [
    "## üìà 16. Monitoreo en Tiempo Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitorear progreso de entrenamiento\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def plot_training_progress(log_file):\n",
    "    \"\"\"Graficar progreso en tiempo real.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(log_file)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss\n",
    "        axes[0, 0].plot(df['epoch'], df['train_loss'], label='Train')\n",
    "        axes[0, 0].plot(df['epoch'], df['val_loss'], label='Val')\n",
    "        axes[0, 0].set_title('Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # mAP\n",
    "        axes[0, 1].plot(df['epoch'], df['val_map'])\n",
    "        axes[0, 1].set_title('mAP@0.5')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # Learning Rate\n",
    "        axes[1, 0].plot(df['epoch'], df['lr'])\n",
    "        axes[1, 0].set_title('Learning Rate')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_yscale('log')\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # GPU Memory\n",
    "        if 'gpu_memory' in df.columns:\n",
    "            axes[1, 1].plot(df['epoch'], df['gpu_memory'])\n",
    "            axes[1, 1].set_title('GPU Memory (GB)')\n",
    "            axes[1, 1].set_xlabel('Epoch')\n",
    "            axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al graficar: {e}\")\n",
    "\n",
    "# Actualizar cada 30 segundos durante entrenamiento\n",
    "LOG_FILE = f\"{LOG_DIR}/training.csv\"\n",
    "\n",
    "# Descomentar para monitoreo en tiempo real (ejecutar en celda separada)\n",
    "# while True:\n",
    "#     clear_output(wait=True)\n",
    "#     plot_training_progress(LOG_FILE)\n",
    "#     time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efdba6",
   "metadata": {},
   "source": [
    "## üßπ 17. Limpieza (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar archivos temporales para liberar espacio\n",
    "!rm -rf /tmp/*\n",
    "!rm -rf ~/.cache/pip\n",
    "!rm -rf data/cache/*\n",
    "\n",
    "# Ver espacio disponible\n",
    "!df -h /content\n",
    "\n",
    "print(\"‚úÖ Limpieza completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b5916",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Recursos Adicionales\n",
    "\n",
    "- **Repositorio**: https://github.com/borysinho/LSB-Temporal-Action-Detection\n",
    "- **Paper Video Swin**: [Video Swin Transformer](https://arxiv.org/abs/2106.13230)\n",
    "- **Documentaci√≥n PyTorch**: https://pytorch.org/docs/\n",
    "\n",
    "---\n",
    "\n",
    "## üìû Soporte\n",
    "\n",
    "¬øProblemas o preguntas? Abre un issue en GitHub.\n",
    "\n",
    "---\n",
    "\n",
    "**Creado con ‚ù§Ô∏è para la comunidad LSB**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
